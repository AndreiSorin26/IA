{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyLinearRegression():\n",
    "    def __init__(self, learning_rate: float = 0.01, regulation_term: float = 0.01, iterations: int = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.regulation_term = regulation_term\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        self.weights = np.zeros((y.shape[1], X.shape[1]))\n",
    "        self.bias = np.zeros(y.shape[1])\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            dW = np.zeros(self.weights.shape)\n",
    "            db = np.zeros(self.bias.shape)\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                y_hat = np.dot(self.weights, X[i]) + self.bias\n",
    "                dW += 2 * np.outer((y_hat - y[i]), X[i])\n",
    "                db += 2 * (y_hat - y[i])\n",
    "            \n",
    "            dW /= X.shape[0]\n",
    "            dW += 2 * self.regulation_term * self.weights\n",
    "            db /= X.shape[0] \n",
    "            \n",
    "            self.weights -= self.learning_rate * dW\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        if self.weights is None or self.bias is None:\n",
    "            raise Exception(\"Model is not trained yet!\")\n",
    "        return np.array(list(map(lambda x: np.dot(self.weights, x) + self.bias, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for custom implementation: 0.8851974823989215\n",
      "R2 score for sklearn implementation: 0.9508460370201635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_data(n: int) -> np.ndarray:\n",
    "    X = np.random.rand(n, 2)\n",
    "    y = np.array([np.array([X[i][0] * 5 + 1, X[i][1] * 4 - 2]) + np.random.rand(2) for i in range(n)])\n",
    "    return X, y\n",
    "\n",
    "r2_score_average_custom = 0\n",
    "r2_score_average_sklearn = 0\n",
    "for _ in range(10):\n",
    "    X, y = generate_data(1000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    lr = MyLinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    r2_score_average_custom += r2_score(y_test, y_pred)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    r2_score_average_sklearn += r2_score(y_test, y_pred)\n",
    "    \n",
    "print(f'R2 score for custom implementation: {r2_score_average_custom / 10}')\n",
    "print(f'R2 score for sklearn implementation: {r2_score_average_sklearn / 10}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Rregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression():\n",
    "    def __init__(self, learning_rate: float = 0.01, regulation_constant: float = 0.0, iterations: int = 1000) -> None:\n",
    "        self.epochs_no = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regulation_constant = regulation_constant\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        x = np.clip(x, -709, 709)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        samples_count, features_count = x.shape\n",
    "        self.weights = np.zeros(features_count)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.epochs_no):\n",
    "            y_predicted = self.__sigmoid(np.dot(x, self.weights) + self.bias)\n",
    "            \n",
    "            dw = (1 / samples_count) * np.dot(x.T, (y_predicted - y)) + self.regulation_constant * self.weights\n",
    "            db = (1 / samples_count) * np.sum(y_predicted - y)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "        \n",
    "    def predict(self, x) -> np.ndarray:\n",
    "        if self.weights is None or self.bias is None:\n",
    "            raise Exception('Model is not trained')\n",
    "        return np.round(self.__sigmoid(np.dot(x, self.weights) + self.bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for custom implementation: 0.8775170197823954\n",
      "F1 score for sklearn implementation: 0.9641852937369295\n",
      "\n",
      "Accuracy score for custom implementation: 0.8670312499999998\n",
      "Accuracy score for sklearn implementation: 0.96265625\n",
      "\n",
      "Precision score for custom implementation: 0.8460295572799493\n",
      "Precision score for sklearn implementation: 0.9675390649331044\n",
      "\n",
      "Recall score for custom implementation: 0.9117407632749366\n",
      "Recall score for sklearn implementation: 0.9609018656923689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "f1_score_average_custom = 0\n",
    "f1_score_average_sklearn = 0\n",
    "\n",
    "accuracy_score_average_custom = 0\n",
    "accuracy_score_average_sklearn = 0\n",
    "\n",
    "precision_score_average_custom = 0\n",
    "precision_score_average_sklearn = 0\n",
    "\n",
    "recall_score_average_custom = 0\n",
    "recall_score_average_sklearn = 0\n",
    "\n",
    "for _ in range(10):\n",
    "    dataset = pd.read_csv('./datasets/chess')\n",
    "    X = dataset.drop('class', axis=1)\n",
    "    y = dataset['class']\n",
    "\n",
    "    for col in X.columns:\n",
    "        labelEncoder = LabelEncoder()\n",
    "        X[col] = labelEncoder.fit_transform(X[col])\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    lr = MyLogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    f1_score_average_custom += f1_score(y_test, y_pred)\n",
    "    accuracy_score_average_custom += accuracy_score(y_test, y_pred)\n",
    "    precision_score_average_custom += precision_score(y_test, y_pred)\n",
    "    recall_score_average_custom += recall_score(y_test, y_pred)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    f1_score_average_sklearn += f1_score(y_test, y_pred)\n",
    "    accuracy_score_average_sklearn += accuracy_score(y_test, y_pred)\n",
    "    precision_score_average_sklearn += precision_score(y_test, y_pred)\n",
    "    recall_score_average_sklearn += recall_score(y_test, y_pred)\n",
    "\n",
    "print(f'F1 score for custom implementation: {f1_score_average_custom / 10}')\n",
    "print(f'F1 score for sklearn implementation: {f1_score_average_sklearn / 10}')\n",
    "print()\n",
    "print(f'Accuracy score for custom implementation: {accuracy_score_average_custom / 10}')\n",
    "print(f'Accuracy score for sklearn implementation: {accuracy_score_average_sklearn / 10}')\n",
    "print()\n",
    "print(f'Precision score for custom implementation: {precision_score_average_custom / 10}')\n",
    "print(f'Precision score for sklearn implementation: {precision_score_average_sklearn / 10}')\n",
    "print()\n",
    "print(f'Recall score for custom implementation: {recall_score_average_custom / 10}')\n",
    "print(f'Recall score for sklearn implementation: {recall_score_average_sklearn / 10}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
